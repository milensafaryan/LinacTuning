{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "3U5gdCw_nSG3"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "  # %tensorflow_version only exists in Colab.\n",
    "  %tensorflow_version 2.x\n",
    "except Exception:\n",
    "  pass\n",
    "\n",
    "# Load the TensorBoard notebook extension.\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "1qIKtOBrqc9Y"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init Plugin\n",
      "Init Graph Optimizer\n",
      "Init Kernel\n",
      "TensorFlow version:  2.5.0\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import io\n",
    "import itertools\n",
    "from packaging import version\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn.metrics\n",
    "\n",
    "print(\"TensorFlow version: \", tf.__version__)\n",
    "assert version.parse(tf.__version__).release[0] >= 2, \\\n",
    "    \"This notebook requires TensorFlow 2.0 or above.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the data. The data is already divided into train and test.\n",
    "# The labels are integers representing classes.\n",
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = \\\n",
    "    fashion_mnist.load_data()\n",
    "\n",
    "# Names of the integer classes, i.e., 0 -> T-short/top, 1 -> Trouser, etc.\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', \n",
    "    'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "train_images = train_images.reshape((train_images.shape[0], 28, 28, 1))\n",
    "test_images = test_images.reshape((test_images.shape[0], 28, 28, 1))\n",
    "# one hot encode target values\n",
    "train_labels = tf.keras.utils.to_categorical(train_labels)\n",
    "test_labels = tf.keras.utils.to_categorical(test_labels)\n",
    "\n",
    "train_norm = train_images.astype('float32')\n",
    "test_norm = test_images.astype('float32')\n",
    "train_norm = train_norm / 255.0\n",
    "test_norm = test_norm / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "R74hPWJHzgvZ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-21 10:33:48.673557: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-03-21 10:33:48.673654: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 28, 28, 64)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 14, 14, 32)        8224      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1568)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               401664    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 412,778\n",
      "Trainable params: 412,778\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=2, padding='same', activation='relu', input_shape=(28,28,1))) \n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
    "model.add(tf.keras.layers.Dropout(0.3))\n",
    "model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=2, padding='same', activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
    "model.add(tf.keras.layers.Dropout(0.3))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "model.summary()\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam', \n",
    "    #loss='sparse_categorical_crossentropy',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_to_image(figure):\n",
    "  \"\"\"Converts the matplotlib plot specified by 'figure' to a PNG image and\n",
    "  returns it. The supplied figure is closed and inaccessible after this call.\"\"\"\n",
    "  # Save the plot to a PNG in memory.\n",
    "  buf = io.BytesIO()\n",
    "  plt.savefig(buf, format='png')\n",
    "  # Closing the figure prevents it from being displayed directly inside\n",
    "  # the notebook.\n",
    "  plt.close(figure)\n",
    "  buf.seek(0)\n",
    "  # Convert PNG buffer to TF image\n",
    "  image = tf.image.decode_png(buf.getvalue(), channels=4)\n",
    "  # Add the batch dimension\n",
    "  image = tf.expand_dims(image, 0)\n",
    "  return image\n",
    "\n",
    "def image_grid():\n",
    "  \"\"\"Return a 5x5 grid of the MNIST images as a matplotlib figure.\"\"\"\n",
    "  # Create a figure to contain the plot.\n",
    "  figure = plt.figure(figsize=(10,10))\n",
    "  for i in range(25):\n",
    "    # Start next subplot.\n",
    "    plt.subplot(5, 5, i + 1, title=class_names[train_labels[i]])\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(train_images[i], cmap=plt.cm.binary)\n",
    "  \n",
    "  return figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "rBiXP8-UO8t6"
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, class_names):\n",
    "  \"\"\"\n",
    "  Returns a matplotlib figure containing the plotted confusion matrix.\n",
    "\n",
    "  Args:\n",
    "    cm (array, shape = [n, n]): a confusion matrix of integer classes\n",
    "    class_names (array, shape = [n]): String names of the integer classes\n",
    "  \"\"\"\n",
    "  figure = plt.figure(figsize=(8, 8))\n",
    "  plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "  plt.title(\"Confusion matrix\")\n",
    "  plt.colorbar()\n",
    "  tick_marks = np.arange(len(class_names))\n",
    "  plt.xticks(tick_marks, class_names, rotation=45)\n",
    "  plt.yticks(tick_marks, class_names)\n",
    "\n",
    "  # Compute the labels from the normalized confusion matrix.\n",
    "  labels = np.around(cm.astype('float') / cm.sum(axis=1)[:, np.newaxis], decimals=2)\n",
    "\n",
    "  # Use white text if squares are dark; otherwise black.\n",
    "  threshold = cm.max() / 2.\n",
    "  for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "    color = \"white\" if cm[i, j] > threshold else \"black\"\n",
    "    plt.text(j, i, labels[i, j], horizontalalignment=\"center\", color=color)\n",
    "\n",
    "  plt.tight_layout()\n",
    "  plt.ylabel('True label')\n",
    "  plt.xlabel('Predicted label')\n",
    "  return figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "bXQ7-9CF0TPA"
   },
   "outputs": [],
   "source": [
    "def log_confusion_matrix(epoch, logs):\n",
    "  # Use the model to predict the values from the validation dataset.\n",
    "  test_pred_raw = model.predict(test_images)\n",
    "  test_pred = np.argmax(test_pred_raw, axis=1)\n",
    "  test_lbl = np.argmax(test_labels, axis=1)  \n",
    "\n",
    "  # Calculate the confusion matrix.\n",
    "  cm = sklearn.metrics.confusion_matrix(test_lbl, test_pred)\n",
    "  # Log the confusion matrix as an image summary.\n",
    "  figure = plot_confusion_matrix(cm, class_names=class_names)\n",
    "  cm_image = plot_to_image(figure)\n",
    "\n",
    "  # Log the confusion matrix as an image summary.\n",
    "  with file_writer_cm.as_default():\n",
    "    tf.summary.image(\"Confusion Matrix\", cm_image, step=epoch)\n",
    "\n",
    "# Define the per-epoch callback.\n",
    "cm_callback = keras.callbacks.LambdaCallback(on_epoch_end=log_confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "utd-vH6hn5RY"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-21 10:34:05.706133: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session initializing.\n",
      "2022-03-21 10:34:05.706146: I tensorflow/core/profiler/lib/profiler_session.cc:141] Profiler session started.\n",
      "2022-03-21 10:34:05.706229: I tensorflow/core/profiler/lib/profiler_session.cc:159] Profiler session tear down.\n"
     ]
    }
   ],
   "source": [
    "# Clear out prior logging data.\n",
    "!rm -rf logs/image\n",
    "\n",
    "logdir = \"logs/image/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "# Define the basic TensorBoard callback.\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "file_writer_cm = tf.summary.create_file_writer(logdir + '/cm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "k6CV7dy-oJZu"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-efffc107eda8f3c4\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-efffc107eda8f3c4\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Start TensorBoard.\n",
    "%tensorboard --logdir logs/image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      " 14/938 [..............................] - ETA: 11s - loss: 0.1929 - accuracy: 0.9230"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-16 14:44:42.109820: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session initializing.\n",
      "2021-09-16 14:44:42.109834: I tensorflow/core/profiler/lib/profiler_session.cc:141] Profiler session started.\n",
      "2021-09-16 14:44:42.126458: I tensorflow/core/profiler/lib/profiler_session.cc:66] Profiler session collecting data.\n",
      "2021-09-16 14:44:42.126973: I tensorflow/core/profiler/lib/profiler_session.cc:159] Profiler session tear down.\n",
      "2021-09-16 14:44:42.127635: I tensorflow/core/profiler/rpc/client/save_profile.cc:137] Creating directory: logs/image/20210916-144430/train/plugins/profile/2021_09_16_14_44_42\n",
      "2021-09-16 14:44:42.128009: I tensorflow/core/profiler/rpc/client/save_profile.cc:143] Dumped gzipped tool data for trace.json.gz to logs/image/20210916-144430/train/plugins/profile/2021_09_16_14_44_42/AD134914-MAC.trace.json.gz\n",
      "2021-09-16 14:44:42.128558: I tensorflow/core/profiler/rpc/client/save_profile.cc:137] Creating directory: logs/image/20210916-144430/train/plugins/profile/2021_09_16_14_44_42\n",
      "2021-09-16 14:44:42.128702: I tensorflow/core/profiler/rpc/client/save_profile.cc:143] Dumped gzipped tool data for memory_profile.json.gz to logs/image/20210916-144430/train/plugins/profile/2021_09_16_14_44_42/AD134914-MAC.memory_profile.json.gz\n",
      "2021-09-16 14:44:42.129055: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: logs/image/20210916-144430/train/plugins/profile/2021_09_16_14_44_42Dumped tool data for xplane.pb to logs/image/20210916-144430/train/plugins/profile/2021_09_16_14_44_42/AD134914-MAC.xplane.pb\n",
      "Dumped tool data for overview_page.pb to logs/image/20210916-144430/train/plugins/profile/2021_09_16_14_44_42/AD134914-MAC.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to logs/image/20210916-144430/train/plugins/profile/2021_09_16_14_44_42/AD134914-MAC.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to logs/image/20210916-144430/train/plugins/profile/2021_09_16_14_44_42/AD134914-MAC.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to logs/image/20210916-144430/train/plugins/profile/2021_09_16_14_44_42/AD134914-MAC.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938/938 [==============================] - 12s 13ms/step - loss: 0.2069 - accuracy: 0.9239 - val_loss: 0.2194 - val_accuracy: 0.9235\n",
      "Epoch 2/15\n",
      "938/938 [==============================] - 12s 13ms/step - loss: 0.2085 - accuracy: 0.9227 - val_loss: 0.2229 - val_accuracy: 0.9213\n",
      "Epoch 3/15\n",
      "938/938 [==============================] - 12s 13ms/step - loss: 0.2060 - accuracy: 0.9219 - val_loss: 0.2199 - val_accuracy: 0.9219\n",
      "Epoch 4/15\n",
      "938/938 [==============================] - 12s 13ms/step - loss: 0.2005 - accuracy: 0.9250 - val_loss: 0.2263 - val_accuracy: 0.9208\n",
      "Epoch 5/15\n",
      "938/938 [==============================] - 12s 13ms/step - loss: 0.2018 - accuracy: 0.9254 - val_loss: 0.2184 - val_accuracy: 0.9232\n",
      "Epoch 6/15\n",
      "938/938 [==============================] - 12s 13ms/step - loss: 0.2004 - accuracy: 0.9243 - val_loss: 0.2149 - val_accuracy: 0.9230\n",
      "Epoch 7/15\n",
      "938/938 [==============================] - 12s 13ms/step - loss: 0.1977 - accuracy: 0.9251 - val_loss: 0.2231 - val_accuracy: 0.9207\n",
      "Epoch 8/15\n",
      "938/938 [==============================] - 12s 12ms/step - loss: 0.1979 - accuracy: 0.9257 - val_loss: 0.2219 - val_accuracy: 0.9238\n",
      "Epoch 9/15\n",
      "938/938 [==============================] - 12s 13ms/step - loss: 0.1938 - accuracy: 0.9267 - val_loss: 0.2200 - val_accuracy: 0.9245\n",
      "Epoch 10/15\n",
      "938/938 [==============================] - 12s 12ms/step - loss: 0.1923 - accuracy: 0.9284 - val_loss: 0.2203 - val_accuracy: 0.9254\n",
      "Epoch 11/15\n",
      "938/938 [==============================] - 12s 13ms/step - loss: 0.1912 - accuracy: 0.9274 - val_loss: 0.2212 - val_accuracy: 0.9217\n",
      "Epoch 12/15\n",
      "938/938 [==============================] - 12s 12ms/step - loss: 0.1877 - accuracy: 0.9290 - val_loss: 0.2220 - val_accuracy: 0.9216\n",
      "Epoch 13/15\n",
      "938/938 [==============================] - 12s 13ms/step - loss: 0.1883 - accuracy: 0.9289 - val_loss: 0.2158 - val_accuracy: 0.9253\n",
      "Epoch 14/15\n",
      "938/938 [==============================] - 12s 13ms/step - loss: 0.1884 - accuracy: 0.9291 - val_loss: 0.2184 - val_accuracy: 0.9241\n",
      "Epoch 15/15\n",
      "938/938 [==============================] - 12s 13ms/step - loss: 0.1883 - accuracy: 0.9280 - val_loss: 0.2172 - val_accuracy: 0.9232\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x28b14e9d0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print(train_norm.shape, train_labels.shape)\n",
    "# Train the classifier.\n",
    "model.fit(\n",
    "    train_norm,\n",
    "    train_labels,\n",
    "    batch_size=64,\n",
    "    epochs=15,\n",
    "    verbose=1, # Suppress chatty output\n",
    "    callbacks=[tensorboard_callback, cm_callback],\n",
    "    validation_data=(test_norm,test_labels)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o7PnxGf8Ur6F"
   },
   "source": [
    "<!-- <img class=\"tfo-display-only-on-site\" src=\"https://github.com/tensorflow/tensorboard/blob/master/docs/images/images_accuracy.png?raw=1\"/> -->\n",
    "\n",
    "<!-- <img class=\"tfo-display-only-on-site\" src=\"https://github.com/tensorflow/tensorboard/blob/master/docs/images/images_cm.png?raw=1\"/> -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "image_summaries.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
